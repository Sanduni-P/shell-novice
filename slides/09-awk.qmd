---
title: "Episode 9: AWK for Text Processing"
subtitle: "Advanced text processing with AWK"
format:
  revealjs:
    theme: default
    transition: slide
    background-transition: fade
    incremental: true
    slide-number: true
---

# Episode 9: AWK for Text Processing

::: {.callout-tip icon="false" .nonincremental}
## Questions

- How do I print specific columns from a text table?
- How can I use patterns to select only certain lines in a file?
- How do I count lines or matched lines in a file?
:::

::: {.callout-tip icon="false" .nonincremental}
## Objectives

- Select and print fields with `$0`, `$1`, `$2`, `$NF`, and `NF`.
- Use a field separator with `-F` to handle CSV input.
- Match lines using simple regex like `/^ATOM/`.
- Count total or matching lines with a counter and the `END` block.
- Explain the difference between `wc -l` and `awk 'END {print NR}'` for line counting.
:::

## What is AWK?

**AWK** = Text processing program

- Reads files line by line
- Splits each line into fields
- Applies pattern-action rules
- Performs calculations and aggregations

Perfect for **CSV and tabular data**!

## Sample Data

A simple data file:

```
chr1  100  200  feature1
chr2  150  300  feature2
chr3  200  400  feature3
```

Columns separated by spaces.

## Basic AWK Pattern

```bash
awk '{action}' file.txt
```

The `{action}` applies to **every line**.

## Simplest Action: Print Everything

```bash
$ awk '{print $0}' data.txt
```

`$0` = the entire line

Same as `cat data.txt`!

## Field Variables: `$1`, `$2`, etc.

Each column is a **field**:

- `$1` = first column
- `$2` = second column
- `$3` = third column
- `$NF` = last column

## Print Specific Columns

**Show first and third columns:**

```bash
$ awk '{print $1, $3}' data.txt
```

```output
chr1 200
chr2 300
chr3 400
```

**Commas add spaces** between columns!

## Print with Custom Text

```bash
$ awk '{print "chr",$2,$4}' data.txt
```

```output
chr 100 feature1
chr 150 feature2
chr 200 feature3
```

Strings go in **quotes**.

## The NF Variable

**NF** = Number of Fields

```bash
$ awk '{print NF}' data.txt
```

```output
4
4
4
```

Each line has 4 fields.

## Last Field: `$NF`

Print the **last field** of each line:

```bash
$ awk '{print $NF}' data.txt
```

```output
feature1
feature2
feature3
```

Works even if lines have **different numbers** of fields!

## Handling Different Field Separators

By default, AWK splits on **spaces and tabs**.

For **comma-separated** (CSV) files:

```bash
$ awk -F "," '{print $2}' data.csv
```

The `-F` flag sets the field separator!

## Field Separator Examples

| Command | Purpose |
|---------|---------|
| `awk -F ":" '{print $1}'` | Colon separator |
| `awk -F "\t" '{print $2}'` | Tab separator |
| `awk -F "," '{print $3}'` | Comma separator |
| `awk '{print $2}'` | Default (space/tab) |

## Pattern-Action Model

Apply action **only** to matching lines:

```bash
awk '/PATTERN/ {action}' file
```

- **Pattern**: lines to match (regex)
- **Action**: what to do with matching lines

## Pattern Example: Start of Line

Find lines starting with "ATOM":

```bash
$ awk '/^ATOM/ {print}' protein.pdb
```

Shows **only** lines beginning with "ATOM".

## Pattern Example: Specific Column

Process lines where column 2 > 100:

```bash
$ awk '$2 > 100 {print $0}' data.txt
```

```output
chr1  150  300  feature2
chr3  200  400  feature3
```

## Multiple Patterns

Apply different actions to different patterns:

```bash
awk '/^ATOM/ {count++} /^HETATM/ {other++} \
    END {print count, other}' protein.pdb
```

## The END Block

**Run after all lines are processed**

Perfect for **printing totals**:

```bash
$ awk '{sum += $2} END {print sum}' data.txt
```

Sums all values in column 2.

## The NR Variable

**NR** = Number of Records (lines)

Total lines in a file:

```bash
$ awk 'END {print NR}' data.txt
```

```output
3
```

More reliable than `wc -l`!

## Counting Lines Robustly

Compare approaches:

```bash
$ wc -l file.txt        # May undercount if no final newline
$ awk 'END {print NR}' file.txt  # Always accurate
```

## Conditional Counting

Count **matching** lines:

```bash
$ awk '/^ATOM/ {count++} END {print count}' protein.pdb
```

Increment counter only for matching lines.

## Safe Counter Initialization

Avoid undefined variable errors:

```bash
$ awk '/^ATOM/ {c++} END {print c+0}' protein.pdb
```

Adding `+0` safely prints 0 if no matches.

## Field Extraction Example

Extract coordinates from PDB:

```bash
$ awk '/^ATOM/ {print $7,$8,$9}' protein.pdb
```

Shows x, y, z coordinates of each atom.

## Arithmetic in AWK

```bash
$ awk '{sum += $1} END {print sum}' numbers.txt
```

Calculate **average**:

```bash
$ awk '{sum += $1; count++} \
       END {print sum/count}' numbers.txt
```

## String Operations

**Length** of a field:

```bash
$ awk '{print length($1)}' data.txt
```

**Concatenation**:

```bash
$ awk '{print $1 "_" $2}' data.txt
```

## Try It Yourself - Question 1

**Given a file with 3 columns of numbers:**

```
10 20 30
5  15 25
```

Write an AWK command to print:
1. Just the second column
2. Just the last column
3. All three columns

## Try It Yourself - Solution 1

**Second column only:**

```bash
$ awk '{print $2}' file.txt
```

```output
20
15
```

**Last column:**

```bash
$ awk '{print $NF}' file.txt
```

**All three:**

```bash
$ awk '{print $1, $2, $3}' file.txt
```

## Try It Yourself - Question 2

**Count total number of lines in a file**

(Use AWK to be sure about the count)

## Try It Yourself - Solution 2

**Robust line counting:**

```bash
$ awk 'END {print NR}' file.txt
```

This is more reliable than `wc -l`!

## Try It Yourself - Question 3

**You have a CSV file with salary data:**

```
name,salary
Alice,50000
Bob,60000
Charlie,55000
```

Calculate the **total salary**.

## Try It Yourself - Solution 3

**Using AWK with CSV:**

```bash
$ awk -F "," 'NR > 1 {sum += $2} \
              END {print sum}' salaries.csv
```

Breaking it down:
- `-F ","` = comma separator
- `NR > 1` = skip header line
- `sum += $2` = add salary column
- `END` = print total

## Try It Yourself - Question 4

**Find lines where column 1 equals "chr1"**

Hint: Use pattern matching

## Try It Yourself - Solution 4

**Matching first column:**

```bash
$ awk '$1 == "chr1" {print}' data.txt
```

Or shorter:

```bash
$ awk '$1 == "chr1"' data.txt
```

(Default action is print)

## Try It Yourself - Question 5

**Count atoms in a PDB file**

(Only count lines starting with "ATOM")

## Try It Yourself - Solution 5

**Count ATOM records:**

```bash
$ awk '/^ATOM/ {count++} END {print count+0}' protein.pdb
```

Or use `grep`:

```bash
$ grep -c "^ATOM" protein.pdb
```

Both work!

## Advanced: Variables in AWK

Define your own variables:

```bash
$ awk 'BEGIN {total=0} {total += $1} \
       END {print total}' data.txt
```

- `BEGIN` runs before processing
- `{total += $1}` in main loop
- `END` prints result

## AWK Programs from Files

For complex AWK scripts, use a file:

Create `count-atoms.awk`:

```awk
/^ATOM/ {
    count++
    x += $7
    y += $8
    z += $9
}

END {
    print "Atoms:", count
    print "Avg X:", x/count
    print "Avg Y:", y/count
    print "Avg Z:", z/count
}
```

Run it:

```bash
$ awk -f count-atoms.awk protein.pdb
```

## Key Points

::: {.fragment}
`$1`, `$2` access **columns**
:::

::: {.fragment}
`$NF` is the **last column**
:::

::: {.fragment}
`$0` is the **entire line**
:::

::: {.fragment}
`-F` sets **field separator**
:::

::: {.fragment}
Patterns select **matching lines**
:::

::: {.fragment}
`END` block runs **after all lines**
:::

::: {.fragment}
`NR` counts **total lines**
:::

::: {.fragment}
Use `count++` for **aggregation**
:::

---

## Thank You!

You've completed the Unix Shell Workshop!

**You now know how to:**

âœ“ Navigate the file system  
âœ“ Manage files and directories  
âœ“ Combine commands with pipes  
âœ“ Automate with loops and scripts  
âœ“ Find files and search text  
âœ“ Process data with AWK  

**Next steps:**

- Practice on your own data
- Read `man` pages for more options
- Build useful scripts for your work
- Share what you learn!

---

**Congratulations! ðŸŽ‰**
